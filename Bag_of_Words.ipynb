{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvZD5PjvXQgOePcDsiPoOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsomsabu/NLP/blob/main/Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfCSOpachQCf",
        "outputId": "35756682-ee89-4e26-d954-d994e4816283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Download 'punkt' from nltk if it's not downloaded\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Text = \"\"\"GeeksForGeeks.\n",
        "Geeks Learning Together.\n",
        "GeeksForGeeks is famous for DSA.\n",
        "Learning DSA\"\"\"\n"
      ],
      "metadata": {
        "id": "cWojmDQLhsKC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TOKENIZATION\n",
        "sentences = sent_tokenize(Text)\n",
        "sentences = [sent.lower().replace(\".\",\"\") for sent in sentences]\n",
        "print('Our Corpus:',sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap4Wi9jlhuXO",
        "outputId": "42f42be4-eaf1-43c9-f79c-0ea70719e338"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Corpus: ['geeksforgeeks', 'geeks learning together', 'geeksforgeeks is famous for dsa', 'learning dsa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CountVectorizer : Convert a collection of text documents to a matrix of token counts.\n",
        "count_vect = CountVectorizer()\n"
      ],
      "metadata": {
        "id": "dvKA3_inhxWh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit & transform will represent each sentences as BOW representation\n",
        "BOW = count_vect.fit_transform(sentences)\n"
      ],
      "metadata": {
        "id": "ZYrz5zMGhz3k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrTRI1Zsh8lp",
        "outputId": "b2b23865-633e-4a55-f2cc-2ba18a2e99eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our vocabulary:  {'geeksforgeeks': 4, 'geeks': 3, 'learning': 6, 'together': 7, 'is': 5, 'famous': 1, 'for': 2, 'dsa': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#see the BOW representation\n",
        "print(f\"BoW representation for {sentences[0]} {BOW[0].toarray()}\")\n",
        "print(f\"BoW representation for {sentences[1]} {BOW[1].toarray()}\")\n",
        "print(f\"BoW representation for {sentences[2]} {BOW[2].toarray()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roZp6m-ph_8s",
        "outputId": "392011c4-cb9c-4279-fad3-70eba92d061f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW representation for geeksforgeeks [[0 0 0 0 1 0 0 0]]\n",
            "BoW representation for geeks learning together [[0 0 0 1 0 0 1 1]]\n",
            "BoW representation for geeksforgeeks is famous for dsa [[1 1 1 0 1 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOW representation for a new text\n",
        "BOW_ = count_vect.transform([\"learning dsa from geeksforgeeks\"])\n",
        "print(\"Bow representation for 'learning dsa from geeksforgeeks':\", BOW_.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtoOksaKiC38",
        "outputId": "34d10766-e3cf-4b2f-c9e9-f487060a0989"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bow representation for 'learning dsa from geeksforgeeks': [[1 0 0 0 1 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# The code demonstrates Bag-of-Words (BoW) representation using CountVectorizer.\n",
        "\n",
        " 1. Tokenization: The text is split into sentences and punctuation is removed.\n",
        "\n",
        " 2. Vocabulary Creation: CountVectorizer builds a vocabulary of unique words from the sentences.\n",
        "\n",
        " 3. BoW Representation: Each sentence is converted into a vector of word counts, indicating the frequency of each vocabulary word in the sentence.\n",
        "\n",
        " 4. New Text Representation: The BoW model can be used to represent new text using the existing vocabulary.\n",
        "\n",
        " Key takeaway: BoW is a simple yet effective way to represent text for machine learning tasks, capturing the frequency of words while ignoring word order and grammar.\n"
      ],
      "metadata": {
        "id": "ygvycnQiiWL0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oec-xlCdiZQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}